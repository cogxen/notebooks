{"cells":[{"source":"# YouTube Comments and Video Stats Analysis\n\n## I. Import Libraries","metadata":{},"cell_type":"markdown","id":"bef0fb9c-7cda-4cc6-a8a5-3c070017931d"},{"source":"import re\nimport string\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom collections import Counter\nfrom textblob import TextBlob\n\n# Natural Language Toolkit\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# Language Detector\ntry:\n    import langid\nexcept ModuleNotFoundError:\n    !pip install langid\n    import langid\n\ntry:\n    from langdetect import detect, LangDetectException\nexcept ModuleNotFoundError:\n    !pip install langdetect\n    from langdetect import detect, LangDetectException\n        \n","metadata":{"executionCancelledAt":null,"executionTime":2484,"lastExecutedAt":1724396705134,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import re\nimport string\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom collections import Counter\nfrom textblob import TextBlob\n\n# Natural Language Toolkit\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# Language Detector\ntry:\n    import langid\nexcept ModuleNotFoundError:\n    !pip install langid\n    import langid\n\ntry:\n    from langdetect import detect, LangDetectException\nexcept ModuleNotFoundError:\n    !pip install langdetect\n    from langdetect import detect, LangDetectException\n        \n","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"3c05c891-f923-4b04-b321-7ade588782e4","outputs":[],"execution_count":1},{"source":"### Download NLTK data files ","metadata":{},"cell_type":"markdown","id":"620614fb-9f8f-480b-bb73-e09fad43a33f"},{"source":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"executionCancelledAt":null,"executionTime":144,"lastExecutedAt":1724396705280,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')"},"cell_type":"code","id":"28bb4633-6aa2-43a0-b632-42232dd708b2","outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/repl/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/repl/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":2}],"execution_count":2},{"source":"### Set up visualization aesthetics","metadata":{},"cell_type":"markdown","id":"d925ab17-9655-4945-99b6-70e516866cf5"},{"source":"sns.set(style=\"whitegrid\")","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396705331,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"sns.set(style=\"whitegrid\")"},"cell_type":"code","id":"247bc0c4-b5e9-42dd-b7ae-f1ca88ac51e4","outputs":[],"execution_count":3},{"source":"## II. Load the Datasets\n\n- Save the datasets in variables","metadata":{},"cell_type":"markdown","id":"76f676e2-c1fd-4b87-b88d-89b7ba502e99"},{"source":"# CSV format\ncomments_csv_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/comments.csv'\nvideo_stats_csv_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/video-stats.csv'\n\n# XLSX format\ncomments_xlsx_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/comments-eng.xlsx'\nvideo_stats_xlsx_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/video-stats-eng.xlsx'","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1724396705379,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# CSV format\ncomments_csv_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/comments.csv'\nvideo_stats_csv_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/video-stats.csv'\n\n# XLSX format\ncomments_xlsx_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/comments-eng.xlsx'\nvideo_stats_xlsx_url = 'https://raw.githubusercontent.com/cogxen/databank/main/youtube-comments-video-stats/video-stats-eng.xlsx'","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"4314187b-d9f9-4a24-8c95-66ca744e84d3","outputs":[],"execution_count":4},{"source":"### (`.csv`) Comments & Video Stats DataFrame \n\n- Comments Data","metadata":{},"cell_type":"markdown","id":"dc5812d7-5f2d-4dd6-b0ff-383ac80f5399"},{"source":"comments_csv = pd.read_csv(comments_csv_url)\ncomments_csv.head()","metadata":{"executionCancelledAt":null,"executionTime":185,"lastExecutedAt":1724396705564,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"comments_csv = pd.read_csv(comments_csv_url)\ncomments_csv.head()"},"cell_type":"code","id":"68b92c9c-b182-47ee-92db-bac53208cda4","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Video ID","type":"string"},{"name":"Comment","type":"string"},{"name":"Likes","type":"integer"},{"name":"Sentiment","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"Video ID":["wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI"],"Comment":["Let's not forget that Apple Pay in 2014 required a brand new iPhone in order to use it.  A significant portion of Apple's user base wasn't able to use it even if they wanted to.  As each successive iPhone incorporated the technology and older iPhones were replaced the number of people who could use the technology increased.","Here in NZ 50% of retailers don’t even have contactless credit card machines like pay-wave which support Apple Pay. They don’t like the high fees that come with these.","I will forever acknowledge this channel with the help of your lessons and ideas explanations, Now It's quite helpful while you'll just sit at your comfort and monitor your account Growth.","Whenever I go to a place that doesn’t take Apple Pay (doesn’t happen too often), it’s such a drag. Between ‘contactless Covid’ habits and my getting the Apple Card, I’ve gotten so used to Apple Pay that I get seriously annoyed when a store doesn’t take it. It feels like a shock, it’s crazy how quickly it took over my shopping routine! I’ve officially been brainwashed by Apple because now it feels so inconvenient to even carry a physical card in my pocket.","Apple Pay is so convenient, secure, and easy to use. I used it while at the Korean and Japanese airports, no need for physical credit cards."],"Likes":[95,19,161,8,34],"Sentiment":[1,0,2,0,2]}},"total_rows":5,"truncation_type":null},"text/plain":"      Video ID  ... Sentiment\n0  wAZZ-UWGVHI  ...         1\n1  wAZZ-UWGVHI  ...         0\n2  wAZZ-UWGVHI  ...         2\n3  wAZZ-UWGVHI  ...         0\n4  wAZZ-UWGVHI  ...         2\n\n[5 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video ID</th>\n      <th>Comment</th>\n      <th>Likes</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n      <td>95</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Here in NZ 50% of retailers don’t even have co...</td>\n      <td>19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>I will forever acknowledge this channel with t...</td>\n      <td>161</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Whenever I go to a place that doesn’t take App...</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Apple Pay is so convenient, secure, and easy t...</td>\n      <td>34</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}],"execution_count":5},{"source":"- Video Stats Data","metadata":{},"cell_type":"markdown","id":"49345eef-4eaf-4e1c-95aa-3a5f0c4a26f5"},{"source":"video_stats_csv = pd.read_csv(video_stats_csv_url)\nvideo_stats_csv.head()","metadata":{"executionCancelledAt":null,"executionTime":122,"lastExecutedAt":1724396705686,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"video_stats_csv = pd.read_csv(video_stats_csv_url)\nvideo_stats_csv.head()"},"cell_type":"code","id":"deacd3c2-621d-4804-ae75-6a9139910282","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Title","type":"string"},{"name":"Video ID","type":"string"},{"name":"Published At","type":"string"},{"name":"Keyword","type":"string"},{"name":"Likes","type":"number"},{"name":"Comments","type":"number"},{"name":"Views","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"Title":["Apple Pay Is Killing the Physical Wallet After Only Eight Years | Tech News Briefing Podcast | WSJ","The most EXPENSIVE thing I own.","My New House Gaming Setup is SICK!","Petrol Vs Liquid Nitrogen | Freezing Experiment | പെട്രോളിനെ ഐസ് ആകാൻ പറ്റുമോ | M4 Tech |","Best Back to School Tech 2022!"],"Video ID":["wAZZ-UWGVHI","b3x28s61q3c","4mgePWWCAmA","kXiYSI7H2b0","ErMwWXQxHp0"],"Published At":["23/08/2022","24/08/2022","23/08/2022","23/08/2022","08/08/2022"],"Keyword":["tech","tech","tech","tech","tech"],"Likes":[3407,76779,63825,71566,96513],"Comments":[672,4306,3338,1426,5155],"Views":[135612,1758063,1564007,922918,1855644]}},"total_rows":5,"truncation_type":null},"text/plain":"                                               Title  ...      Views\n0  Apple Pay Is Killing the Physical Wallet After...  ...   135612.0\n1                    The most EXPENSIVE thing I own.  ...  1758063.0\n2                 My New House Gaming Setup is SICK!  ...  1564007.0\n3  Petrol Vs Liquid Nitrogen | Freezing Experimen...  ...   922918.0\n4                     Best Back to School Tech 2022!  ...  1855644.0\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Video ID</th>\n      <th>Published At</th>\n      <th>Keyword</th>\n      <th>Likes</th>\n      <th>Comments</th>\n      <th>Views</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Apple Pay Is Killing the Physical Wallet After...</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>23/08/2022</td>\n      <td>tech</td>\n      <td>3407.0</td>\n      <td>672.0</td>\n      <td>135612.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The most EXPENSIVE thing I own.</td>\n      <td>b3x28s61q3c</td>\n      <td>24/08/2022</td>\n      <td>tech</td>\n      <td>76779.0</td>\n      <td>4306.0</td>\n      <td>1758063.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>My New House Gaming Setup is SICK!</td>\n      <td>4mgePWWCAmA</td>\n      <td>23/08/2022</td>\n      <td>tech</td>\n      <td>63825.0</td>\n      <td>3338.0</td>\n      <td>1564007.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Petrol Vs Liquid Nitrogen | Freezing Experimen...</td>\n      <td>kXiYSI7H2b0</td>\n      <td>23/08/2022</td>\n      <td>tech</td>\n      <td>71566.0</td>\n      <td>1426.0</td>\n      <td>922918.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Best Back to School Tech 2022!</td>\n      <td>ErMwWXQxHp0</td>\n      <td>08/08/2022</td>\n      <td>tech</td>\n      <td>96513.0</td>\n      <td>5155.0</td>\n      <td>1855644.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}],"execution_count":6},{"source":"### (`.xlsx`) Comments & Video Stats\n\n- Comments Data","metadata":{},"cell_type":"markdown","id":"f3c6d540-11d7-43bc-b547-2b4f917f8f33"},{"source":"comments_xlsx = pd.read_excel(comments_xlsx_url)\ncomments_xlsx.head()","metadata":{"executionCancelledAt":null,"executionTime":1716,"lastExecutedAt":1724396707402,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"comments_xlsx = pd.read_excel(comments_xlsx_url)\ncomments_xlsx.head()"},"cell_type":"code","id":"149c53c7-c661-4bd2-9f59-7fd18aba7545","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Video ID","type":"string"},{"name":"Comment","type":"string"},{"name":"Likes","type":"integer"},{"name":"Sentiment","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"Video ID":["wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI","wAZZ-UWGVHI"],"Comment":["Let's not forget that Apple Pay in 2014 required a brand new iPhone in order to use it.  A significant portion of Apple's user base wasn't able to use it even if they wanted to.  As each successive iPhone incorporated the technology and older iPhones were replaced the number of people who could use the technology increased.","Here in NZ 50% of retailers don’t even have contactless credit card machines like pay-wave which support Apple Pay. They don’t like the high fees that come with these.","I will forever acknowledge this channel with the help of your lessons and ideas explanations, Now It's quite helpful while you'll just sit at your comfort and monitor your account Growth.","Whenever I go to a place that doesn’t take Apple Pay (doesn’t happen too often), it’s such a drag. Between ‘contactless Covid’ habits and my getting the Apple Card, I’ve gotten so used to Apple Pay that I get seriously annoyed when a store doesn’t take it. It feels like a shock, it’s crazy how quickly it took over my shopping routine! I’ve officially been brainwashed by Apple because now it feels so inconvenient to even carry a physical card in my pocket.","Apple Pay is so convenient, secure, and easy to use. I used it while at the Korean and Japanese airports, no need for physical credit cards."],"Likes":[95,19,161,8,34],"Sentiment":[1,0,2,0,2]}},"total_rows":5,"truncation_type":null},"text/plain":"      Video ID  ... Sentiment\n0  wAZZ-UWGVHI  ...         1\n1  wAZZ-UWGVHI  ...         0\n2  wAZZ-UWGVHI  ...         2\n3  wAZZ-UWGVHI  ...         0\n4  wAZZ-UWGVHI  ...         2\n\n[5 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video ID</th>\n      <th>Comment</th>\n      <th>Likes</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n      <td>95</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Here in NZ 50% of retailers don’t even have co...</td>\n      <td>19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>I will forever acknowledge this channel with t...</td>\n      <td>161</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Whenever I go to a place that doesn’t take App...</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wAZZ-UWGVHI</td>\n      <td>Apple Pay is so convenient, secure, and easy t...</td>\n      <td>34</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":7}],"execution_count":7},{"source":"- Video Stats Data","metadata":{},"cell_type":"markdown","id":"34564093-a1ed-4114-98de-deb2734b5e02"},{"source":"video_stats_xlsx = pd.read_excel(video_stats_xlsx_url)\nvideo_stats_xlsx.head()","metadata":{"executionCancelledAt":null,"executionTime":328,"lastExecutedAt":1724396707730,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"video_stats_xlsx = pd.read_excel(video_stats_xlsx_url)\nvideo_stats_xlsx.head()"},"cell_type":"code","id":"33e02392-b7a1-4d0a-8ab6-c43bcdcf6204","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Title","type":"string"},{"name":"Video ID","type":"string"},{"name":"Published At","type":"datetime"},{"name":"Keyword","type":"string"},{"name":"Likes","type":"integer"},{"name":"Comments","type":"integer"},{"name":"Views","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"Title":["Apple Pay Is Killing the Physical Wallet After Only Eight Years | Tech News Briefing Podcast | WSJ","The most EXPENSIVE thing I own.","My New House Gaming Setup is SICK!","Best Back to School Tech 2022!","Brewmaster Answers Beer Questions From Twitter | Tech Support | WIRED"],"Video ID":["wAZZ-UWGVHI","b3x28s61q3c","4mgePWWCAmA","ErMwWXQxHp0","18fwz9Itbvo"],"Published At":["2022-08-23T00:00:00.000","2022-08-24T00:00:00.000","2022-08-23T00:00:00.000","2022-08-08T00:00:00.000","2021-11-05T00:00:00.000"],"Keyword":["tech","tech","tech","tech","tech"],"Likes":[3407,76779,63825,96513,33570],"Comments":[672,4306,3338,5155,1643],"Views":[135612,1758063,1564007,1855644,943119]}},"total_rows":5,"truncation_type":null},"text/plain":"                                               Title  ...    Views\n0  Apple Pay Is Killing the Physical Wallet After...  ...   135612\n1                    The most EXPENSIVE thing I own.  ...  1758063\n2                 My New House Gaming Setup is SICK!  ...  1564007\n3                     Best Back to School Tech 2022!  ...  1855644\n4  Brewmaster Answers Beer Questions From Twitter...  ...   943119\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Video ID</th>\n      <th>Published At</th>\n      <th>Keyword</th>\n      <th>Likes</th>\n      <th>Comments</th>\n      <th>Views</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Apple Pay Is Killing the Physical Wallet After...</td>\n      <td>wAZZ-UWGVHI</td>\n      <td>2022-08-23</td>\n      <td>tech</td>\n      <td>3407</td>\n      <td>672</td>\n      <td>135612</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The most EXPENSIVE thing I own.</td>\n      <td>b3x28s61q3c</td>\n      <td>2022-08-24</td>\n      <td>tech</td>\n      <td>76779</td>\n      <td>4306</td>\n      <td>1758063</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>My New House Gaming Setup is SICK!</td>\n      <td>4mgePWWCAmA</td>\n      <td>2022-08-23</td>\n      <td>tech</td>\n      <td>63825</td>\n      <td>3338</td>\n      <td>1564007</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Best Back to School Tech 2022!</td>\n      <td>ErMwWXQxHp0</td>\n      <td>2022-08-08</td>\n      <td>tech</td>\n      <td>96513</td>\n      <td>5155</td>\n      <td>1855644</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brewmaster Answers Beer Questions From Twitter...</td>\n      <td>18fwz9Itbvo</td>\n      <td>2021-11-05</td>\n      <td>tech</td>\n      <td>33570</td>\n      <td>1643</td>\n      <td>943119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":8}],"execution_count":8},{"source":"- Define file paths and options\n- Load the datasets\n    - Rename the columns\n- Check data integrity  ","metadata":{},"cell_type":"markdown","id":"e563680e-8d08-43b9-adeb-f94bdda3ffd8"},{"source":"# Defile file paths and options based on the source\ndata_source = 'eff'\n\nif data_source == 'org':\n    print('Loading original source...')\n    comments_file = comments_csv_url\n    video_stats_file = video_stats_csv_url\n    load_function = pd.read_csv\n    load_options = {'parse_dates': ['Published At'], 'dayfirst': True}\n    comments_columns_mapping = []\nelse:\n    print('Loading efficient source...')\n    comments_file = comments_xlsx_url\n    video_stats_file = video_stats_xlsx_url\n    load_function = pd.read_excel\n    load_options = {}\n    comments_columns_mapping = ['Video ID', 'Comment', 'Comment_Likes', 'Comment_Sentiment']\n    \n# Load the datasets\nvideo_stats = load_function(video_stats_file, **load_options)\ncomments = load_function(comments_file, **load_options)\n\n# Rename columns\nif data_source != 'org':\n    comments.columns = comments_columns_mapping\n    \n# Definitions\nmetrics = ['Views', 'Likes', 'Comments']\n\n# Checks data integrity\ninitial_shape = video_stats.shape\nprint(f'Initial shape of video stats: {initial_shape}')\nduplicate_count = initial_shape[0] - video_stats[['Title', 'Published At', 'Keyword', 'Likes', 'Comments', 'Views']].drop_duplicates().shape[0]\nprint(f'Number of duplicate rows: {duplicate_count}')","cell_type":"code","id":"22672518-ce6e-47ec-8505-f904afb635f1","outputs":[{"output_type":"stream","name":"stdout","text":"Loading efficient source...\nInitial shape of video stats: (1577, 7)\nNumber of duplicate rows: 0\n"}],"execution_count":9,"metadata":{"executionCancelledAt":null,"executionTime":1741,"lastExecutedAt":1724396709471,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Defile file paths and options based on the source\ndata_source = 'eff'\n\nif data_source == 'org':\n    print('Loading original source...')\n    comments_file = comments_csv_url\n    video_stats_file = video_stats_csv_url\n    load_function = pd.read_csv\n    load_options = {'parse_dates': ['Published At'], 'dayfirst': True}\n    comments_columns_mapping = []\nelse:\n    print('Loading efficient source...')\n    comments_file = comments_xlsx_url\n    video_stats_file = video_stats_xlsx_url\n    load_function = pd.read_excel\n    load_options = {}\n    comments_columns_mapping = ['Video ID', 'Comment', 'Comment_Likes', 'Comment_Sentiment']\n    \n# Load the datasets\nvideo_stats = load_function(video_stats_file, **load_options)\ncomments = load_function(comments_file, **load_options)\n\n# Rename columns\nif data_source != 'org':\n    comments.columns = comments_columns_mapping\n    \n# Definitions\nmetrics = ['Views', 'Likes', 'Comments']\n\n# Checks data integrity\ninitial_shape = video_stats.shape\nprint(f'Initial shape of video stats: {initial_shape}')\nduplicate_count = initial_shape[0] - video_stats[['Title', 'Published At', 'Keyword', 'Likes', 'Comments', 'Views']].drop_duplicates().shape[0]\nprint(f'Number of duplicate rows: {duplicate_count}')"}},{"source":"## III. Helper Functions\n\n### Text Preprocessing Method\n\n- (`preprocess_text`), a fundamental step in natural language processing, involves transforming raw text data into a structured format suitable for analysis by converting text to lowercase, removing punctuation and stop words, tokenizing, and lemmatizing, ultimately rejoining the tokens into a single string. This process is crucial for enabling effective natural language processing tasks.","metadata":{},"cell_type":"markdown","id":"6aa34208-3b8e-428e-ad5c-d954e4ace9e3"},{"source":"def preprocess_text(raw_text):\n    # Ensure the input is a string\n    if not isinstance(raw_text, str):\n        raw_text = str(raw_text)\n    \n    # Convert text to lowercase\n    text_lower = raw_text.lower()\n    \n    # Remove punctuation\n    text_no_punct = text_lower.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenize the text\n    word_tokens = word_tokenize(text_no_punct)\n    \n    # Remove stopwords and punctuation tokens\n    stopwords_set = set(stopwords.words('english'))\n    filtered_tokens = [word for word in word_tokens if word not in stopwords_set and word not in string.punctuation]\n    \n    # Lemmatize the tokens\n    lemmatizer = WordNetLemmatizer()\n    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n    \n    # Rejoin the tokens into a single string\n    preprocessed_text = ' '.join(lemmatized_tokens)\n    \n    return preprocessed_text","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396709522,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def preprocess_text(raw_text):\n    # Ensure the input is a string\n    if not isinstance(raw_text, str):\n        raw_text = str(raw_text)\n    \n    # Convert text to lowercase\n    text_lower = raw_text.lower()\n    \n    # Remove punctuation\n    text_no_punct = text_lower.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenize the text\n    word_tokens = word_tokenize(text_no_punct)\n    \n    # Remove stopwords and punctuation tokens\n    stopwords_set = set(stopwords.words('english'))\n    filtered_tokens = [word for word in word_tokens if word not in stopwords_set and word not in string.punctuation]\n    \n    # Lemmatize the tokens\n    lemmatizer = WordNetLemmatizer()\n    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n    \n    # Rejoin the tokens into a single string\n    preprocessed_text = ' '.join(lemmatized_tokens)\n    \n    return preprocessed_text"},"cell_type":"code","id":"81ecdac3-438b-4a2f-88be-7b792c5328aa","outputs":[],"execution_count":10},{"source":"### Language Determination Method\n\n- (`determine_language`), it employs a hybrid approach, leveraging both `langdetect` and `langid` libraries to identify the dominant language within a given text. It returns 'en' if either library confidently detects English; otherwise, it classifies the language as 'unknown'. This strategy is particularly valuable for applications that handle multilingual content and necessitate a robust language identification mechanism with a fallback option.","metadata":{},"cell_type":"markdown","id":"6bc51c4b-e26b-4e27-b41e-3b295adf3a7a"},{"source":"# Function to determine the language of a given text using langdetect\ndef determine_language_langdetect(text):\n    try:\n        return detect(text)\n    except LangDetectException:\n        return \"unknown\"\n\n# Function to determine the language of a given text using langid\ndef determine_language_langid(text):\n    language, _ = langid.classify(text)\n    return language\n\n# Combined function to determine the language using both methods\ndef determine_language(text):\n    lang_langdetect = determine_language_langdetect(text)\n    lang_langid = determine_language_langid(text)\n    \n    if lang_langdetect == 'en' or lang_langid == 'en':\n        return 'en'\n    else:\n        return 'unknown'","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1724396709571,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Function to determine the language of a given text using langdetect\ndef determine_language_langdetect(text):\n    try:\n        return detect(text)\n    except LangDetectException:\n        return \"unknown\"\n\n# Function to determine the language of a given text using langid\ndef determine_language_langid(text):\n    language, _ = langid.classify(text)\n    return language\n\n# Combined function to determine the language using both methods\ndef determine_language(text):\n    lang_langdetect = determine_language_langdetect(text)\n    lang_langid = determine_language_langid(text)\n    \n    if lang_langdetect == 'en' or lang_langid == 'en':\n        return 'en'\n    else:\n        return 'unknown'"},"cell_type":"code","id":"4ff4ac27-12a7-40c9-9f37-c9902e4d70c9","outputs":[],"execution_count":11},{"source":"### Sentiment Classification Method\n\n- (`classify_sentiment`), it maps polarity scores to their respective sentiment categories ('Negative',\n 'Neutral', or 'Positive'), providing a valuable tool for applications requiring text categorization based on sentiment analysis.","metadata":{},"cell_type":"markdown","id":"3baace3c-cef3-4e06-8ce6-8a5ddd1743a6"},{"source":"def classift_sentiment(polarity_score):\n    if polarity_score < -0.2:\n        return 'Negative'\n    elif polarity_score < 0.2:\n        return 'Neutral'\n    else:\n        return 'Positive'","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1724396709620,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def classift_sentiment(polarity_score):\n    if polarity_score < -0.2:\n        return 'Negative'\n    elif polarity_score < 0.2:\n        return 'Neutral'\n    else:\n        return 'Positive'"},"cell_type":"code","id":"9cecdb04-cbf7-4eff-b387-232325bba09d","outputs":[],"execution_count":12},{"source":"### Sentiment Analysis Method\n\n- (`analyze_sentiment`), it analyzes the sentiment of the input text using the TextBlob library and returns the polarity score, which is useful for understanding the emotional tone of the text.","metadata":{},"cell_type":"markdown","id":"8519a58e-ff23-4ed2-8e4c-134f9d6bd52d"},{"source":"def analyze_sentiment(input_text):\n    if not isinstance(input_text, str):\n        input_text = str(input_text)\n    \n    tb = TextBlob(input_text)\n    return tb.sentiment.polarity","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1724396709668,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def analyze_sentiment(input_text):\n    if not isinstance(input_text, str):\n        input_text = str(input_text)\n    \n    tb = TextBlob(input_text)\n    return tb.sentiment.polarity"},"cell_type":"code","id":"d5de6653-491d-436f-9c96-465ceb763d6e","outputs":[],"execution_count":13},{"source":"### Text Length Calculation Method\n\n- (`calculate_text_length`), it calculates the length of the input text, converting it to a string if necessary.","metadata":{},"cell_type":"markdown","id":"af04f37e-7164-472b-8780-87840815f06c"},{"source":"def calculate_text_length(input_text):\n    if not isinstance(input_text, str):\n        input_text = str(input_text)\n    return len(input_text)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1724396709715,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def calculate_text_length(input_text):\n    if not isinstance(input_text, str):\n        input_text = str(input_text)\n    return len(input_text)"},"cell_type":"code","id":"5046af0a-07ed-47fc-b171-6fcbf26b19c9","outputs":[],"execution_count":14},{"source":"### Text Type Check Method\n\n- (`is_text_string`), it checks if the input is a string and returns a boolean value indicating the result.","metadata":{},"cell_type":"markdown","id":"d40c0900-d33f-4518-91fc-049a41da6123"},{"source":"def is_text_string(input_text):\n    return isinstance(input_text, str)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396709767,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def is_text_string(input_text):\n    return isinstance(input_text, str)"},"cell_type":"code","id":"3f75c73b-b175-481c-885a-b3701ffc60f5","outputs":[],"execution_count":15},{"source":"### Engagement Rate Computation Method\n\n- (`compute_engagement_rate`), it computes the engagement rate based on the number of likes, comments, and views, with optional weights for likes and comments. This method is useful for social media analytics and content performance evaluation.\n\n**Paramaters**\n1. `likes` (`int`): The number of likes.\n2. `comments` (`int`): The number of comments.\n3. `views` (`int`): The number of views.\n4. `like_weight` (`float`, `optional`): The weight assigned to likes. Default is 1.\n5. `comment_weight` (`float`, `optional`): The weight assigned to comments. Default is 1.5.\n\n**Returns**\n- `float`: The engagement rate as a percentage.","metadata":{},"cell_type":"markdown","id":"8a307aab-6c9d-4d52-b0c7-8f7e3f8c212e"},{"source":"def compute_engagement_rate(likes, comments, views, like_weight=1, comment_weight=1.5):\n    if views == 0:\n        return 0\n    return ((like_weight * likes + comment_weight * comments) / views) * 100","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1724396709815,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def compute_engagement_rate(likes, comments, views, like_weight=1, comment_weight=1.5):\n    if views == 0:\n        return 0\n    return ((like_weight * likes + comment_weight * comments) / views) * 100"},"cell_type":"code","id":"5b9a58ea-3425-41d9-a65e-c89e9a6d1ebe","outputs":[],"execution_count":16},{"source":"### Sort Order Generation Method\n\n- (`generate_sort_order`), it generates a sort order based on the median of a specified metric for groups in the dataframe, which is useful for ranking groups by their performance on various metrics.\n\n**Parameters**\n1. `dataframe` (`pd.DataFrame`): The dataframe containing the data.\n2. `group_column` (`str`): The column to group by.\n\n**Returns**\n- `list`: A list of group names sorted by their median engagement rate in descending order.","metadata":{},"cell_type":"markdown","id":"a9c8a168-5f55-43c0-94c2-c803e1349a27"},{"source":"def generate_sort_order(dataframe, group_column, metric_column):\n    group_medians = dataframe.groupby(group_column)[metric_column].median().sort_values(ascending=False)\n    sort_order = group_medians.index.tolist()\n    return sort_order","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1724396709867,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def generate_sort_order(dataframe, group_column, metric_column):\n    group_medians = dataframe.groupby(group_column)[metric_column].median().sort_values(ascending=False)\n    sort_order = group_medians.index.tolist()\n    return sort_order"},"cell_type":"code","id":"de873c96-3088-4c99-ab62-479424342ffc","outputs":[],"execution_count":17},{"source":"### Median Metric by Group Plotting Method\n\n- (`plot_median_metric_by_group`), it plots the median of a specified metric by group, which is useful for visualizing the performance of groups on various metrics.\n\n**Parameters**\n1. `dataframe` (`pd.DataFrame`): The dataframe containing the data.\n2. `group_column` (`str`): The column to group by.\n3. `metric_column` (`str`, `optional`): The column representing the metric to plot.","metadata":{},"cell_type":"markdown","id":"475b127a-5d42-4f63-8a02-ecafcd7bc572"},{"source":"def plot_median_metric_by_group(dataframe, group_column, metric_column):\n    # Calculaate the median of the specified metric by group and sort by value\n    grouped_median = dataframe.groupby(group_column)[metric_column].median().sort_values(ascending=False).reset_index()\n    \n    # Melt the dataframe for plotting    \n    melted_data = grouped_medians.melt(id_vars=[group_column])\n    melted_data.columns = [group_column, 'Metric', 'Value']\n    \n    # Filter for the specified metric and sort by value\n    filtered_data = melted_data[melted_data['Metric'] == metric_column].sort_values(by='Value', ascending=False)\n    \n    # Plot the data\n    sns.barplot(data=filtered_data, y=group_column, x='Value')","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396709919,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def plot_median_metric_by_group(dataframe, group_column, metric_column):\n    # Calculaate the median of the specified metric by group and sort by value\n    grouped_median = dataframe.groupby(group_column)[metric_column].median().sort_values(ascending=False).reset_index()\n    \n    # Melt the dataframe for plotting    \n    melted_data = grouped_medians.melt(id_vars=[group_column])\n    melted_data.columns = [group_column, 'Metric', 'Value']\n    \n    # Filter for the specified metric and sort by value\n    filtered_data = melted_data[melted_data['Metric'] == metric_column].sort_values(by='Value', ascending=False)\n    \n    # Plot the data\n    sns.barplot(data=filtered_data, y=group_column, x='Value')"},"cell_type":"code","id":"e9048412-bc51-4bc4-9b62-c29bdf307e08","outputs":[],"execution_count":18},{"source":"### Outlier Removal by Category Method\n\n- (`remove_outliers_by_category`), it removes outliers from the DataFrame based on the category of the item using the Interquartile Range (IQR) method, which is useful for cleaning data before analysis.\n\n**Parameters**\n1. `dataframe` (`pd.DataFrame`): The input DataFrame.\n2. `category_column` (`str`): The name of the category column.\n3. `value_column` (`str`): The name of the value column.\n\n**Returns**\n- `pd.DataFrame`: The DataFrame with outliers removed.","metadata":{},"cell_type":"markdown","id":"3c2c8764-e7f5-428a-a559-126f8feaf40b"},{"source":"def remove_outliers_by_category(dataframe, category_column, value_column):\n    def filter_outliers(group):\n        q1 = group[value_column].quantile(0.25)\n        q3 = group[value_column].quantile(0.75)\n        iqr = q3 - q1\n        lower_bound = q1 - 1.5 * iqr\n        upper_bound = q3 + 1.5 * iqr\n        return group[group[value_column].between(lower_bound, upper_bound)]\n    \n    return data.groupby(category_col).apply(filter_outliers).reset_index(drop=True)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1724396709971,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def remove_outliers_by_category(dataframe, category_column, value_column):\n    def filter_outliers(group):\n        q1 = group[value_column].quantile(0.25)\n        q3 = group[value_column].quantile(0.75)\n        iqr = q3 - q1\n        lower_bound = q1 - 1.5 * iqr\n        upper_bound = q3 + 1.5 * iqr\n        return group[group[value_column].between(lower_bound, upper_bound)]\n    \n    return data.groupby(category_col).apply(filter_outliers).reset_index(drop=True)"},"cell_type":"code","id":"d5afe16b-1392-407e-88be-31f42000941d","outputs":[],"execution_count":19},{"source":"### Token Filtering & Most Common Tokens by Category Extraction Method\n\n- (`filter_non_alphanumeric_tokens`), it filters out tokens that are purely numeric or single characters, which is useful for cleaning tokenized text data.","metadata":{},"cell_type":"markdown","id":"d300c36c-e061-476e-b0ff-8d7060cfdc19"},{"source":"def filter_non_alphanumeric_tokens(tokens):\n    return [str(token) for token in tokens if not re.match(r'^\\d+$|^.{1}$', str(token))]            ","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1724396710019,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def filter_non_alphanumeric_tokens(tokens):\n    return [str(token) for token in tokens if not re.match(r'^\\d+$|^.{1}$', str(token))]            "},"cell_type":"code","id":"41f9416e-8e6a-4db2-a8f9-baa82ae38571","outputs":[],"execution_count":20},{"source":"- (`get_most_common_tokens_by_category`), it extracts the most common tokens for each category in the dataframe, which is useful for analyzing the most frequent terms in different categories.\n\n**Parameters** (`get_most_common_tokens_by_category`)\n1. `dataframe` (`pd.DataFrame`): The input dataframe.\n2. `category_column` (`str`): The name of the column containing category information.\n3. `tokens_column` (`str`): The name of the column containing tokens.\n4. `top_n` (`int`, `optional`): The number of most common tokens to return. Default is 3.\n\n**Returns**\n- `dict`: A dictionary where keys are categories and values are lists of the most common tokens.","metadata":{},"cell_type":"markdown","id":"eb13e152-2f92-42a4-be4b-5014d001411f"},{"source":"def get_most_common_tokens_by_category(dataframe, category_column, tokens_column, top_n=3):\n    # Group the dataframe by the specified category column\n    grouped = dataframe.groupby(category_column)\n    \n    # Initialize a dictionary to store the most common tokens for each category\n    common_tokens = {}\n    \n    # Iterate through each group (category)\n    for category, group in grouped:\n        all_tokens = []\n        # Collect all tokens from the specified tokens column, filtering out non-alphanumeric tokens\n        for tokens in group[tokens_column]:\n            filtered_tokens = filter_non_alphanumeric_tokens(tokens)\n            all_tokens.extend(filtered_tokens)\n            \n        # Count the frequency of each token\n        token_counts = Counter(all_tokens)\n        \n        # Retrieve the top_n most common tokens for the current category\n        common_tokens[category] = token_counts.most_common(top_n)\n        \n    return common_tokens","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396710071,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def get_most_common_tokens_by_category(dataframe, category_column, tokens_column, top_n=3):\n    # Group the dataframe by the specified category column\n    grouped = dataframe.groupby(category_column)\n    \n    # Initialize a dictionary to store the most common tokens for each category\n    common_tokens = {}\n    \n    # Iterate through each group (category)\n    for category, group in grouped:\n        all_tokens = []\n        # Collect all tokens from the specified tokens column, filtering out non-alphanumeric tokens\n        for tokens in group[tokens_column]:\n            filtered_tokens = filter_non_alphanumeric_tokens(tokens)\n            all_tokens.extend(filtered_tokens)\n            \n        # Count the frequency of each token\n        token_counts = Counter(all_tokens)\n        \n        # Retrieve the top_n most common tokens for the current category\n        common_tokens[category] = token_counts.most_common(top_n)\n        \n    return common_tokens"},"cell_type":"code","id":"0c380bb6-00ab-4790-9408-68ba1fc2d34f","outputs":[],"execution_count":21},{"source":"### Keyword Extraction Method\n\n-  (`find_keywords`), it extracts keywords from a given text that are present in a provided list of keywords, which is useful for categorizing or tagging text based on their content. \n\n**Parameters**\n1. `text` (`str`): The text to search for keywords.\n2. `keyword_list` (`list`): A list of keywords to search for in the text.\n\n**Returns**\n- `list`: A list of found keywords or ['other'] if no keywords are found.","metadata":{},"cell_type":"markdown","id":"59923b5c-85ce-4c09-a901-9e495f00b9b5"},{"source":"def find_keywords(text, keyword_list):\n    found_keywords = [keyword for keyword in keyword_lit in keyword in text]\n    return found_keywords if found_keywords else ['other']","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1724396710123,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def find_keywords(text, keyword_list):\n    found_keywords = [keyword for keyword in keyword_lit in keyword in text]\n    return found_keywords if found_keywords else ['other']"},"cell_type":"code","id":"0575d22f-7838-4d70-b875-830223080e9b","outputs":[],"execution_count":22},{"source":"## IV. (EDA) Data Preprocessing & Cleaning\n\n### Engagement Metrics Cleaning\n\n- Replace all negative values in engangement metrics with `NaN` and fills missing values with the median, which is useful for ensuring data and preparing the data for analysis.\n\n#### Video Stats Data","metadata":{},"cell_type":"markdown","id":"6b14f92d-03e1-4cec-8443-07f756dc3a73"},{"source":"metrics = ['Views', 'Likes', 'Comments']\n\n# Replace negative values in engagement metrics with NaN\nfor metric in metrics:\n    video_stats.loc[video_stats[metric] < 0 , metric] = pd.NA\n    \n# Fill missing values with median of each metric\nfor metric in metrics:\n    median_value = video_stats[metric].median()\n    video_stats[metric].fillna(median_value, inplace=True)\n    \n# Check the dataframe to ensure cleaning process\nprint(f'Cleaned DataFrame shape: {video_stats.shape}')","metadata":{"executionCancelledAt":null,"executionTime":57,"lastExecutedAt":1724396710180,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"metrics = ['Views', 'Likes', 'Comments']\n\n# Replace negative values in engagement metrics with NaN\nfor metric in metrics:\n    video_stats.loc[video_stats[metric] < 0 , metric] = pd.NA\n    \n# Fill missing values with median of each metric\nfor metric in metrics:\n    median_value = video_stats[metric].median()\n    video_stats[metric].fillna(median_value, inplace=True)\n    \n# Check the dataframe to ensure cleaning process\nprint(f'Cleaned DataFrame shape: {video_stats.shape}')","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"a5d06dd9-d46a-41b9-8188-e21f68c8c592","outputs":[{"output_type":"stream","name":"stdout","text":"Cleaned DataFrame shape: (1577, 7)\n"}],"execution_count":23},{"source":"#### Comments Data","metadata":{},"cell_type":"markdown","id":"70154cff-d7b4-42c6-9839-d578bea2eac7"},{"source":"comments.isnull().sum()","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1724396710236,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"comments.isnull().sum()"},"cell_type":"code","id":"b7569bd9-af41-4d5d-92d2-d67ab5a64493","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"0","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":[224,1,0,0],"index":["Video ID","Comment","Comment_Likes","Comment_Sentiment"]}},"total_rows":4,"truncation_type":null},"text/plain":"Video ID             224\nComment                1\nComment_Likes          0\nComment_Sentiment      0\ndtype: int64"},"metadata":{},"execution_count":24}],"execution_count":24},{"source":"### Data Filtering & Language Detection\n\n- It filters out videos with no vies, cleans the title, detects the language, and filters out non-English titles, which is useful for ensuring data quality and consistency.\n\n#### Video Stats Data\n\n- Filter out no views videos","metadata":{},"cell_type":"markdown","id":"50bd7e8c-db7b-4e51-ba20-9c545ee1a10f"},{"source":"# Filter out rows where 'Views' is greater than 0\nvideo_stats = video_stats[video_stats['Views'] > 0] \n\n# Check how many rows with no views were removed\nprint(f\"Removed {initial_shape[0] - video_stats.shape[0]} rows after filtering views\")","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1724396710288,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Filter out rows where 'Views' is greater than 0\nvideo_stats = video_stats[video_stats['Views'] > 0] \n\n# Check how many rows with no views were removed\nprint(f\"Removed {initial_shape[0] - video_stats.shape[0]} rows after filtering views\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"e7aee481-16c4-4db8-adae-51398a1ee214","outputs":[{"output_type":"stream","name":"stdout","text":"Removed 2 rows after filtering views\n"}],"execution_count":25},{"source":"#### Comments Data\n\n- Drop rows with missing values","metadata":{},"cell_type":"markdown","id":"49a97503-9bf7-433d-bad2-e0079ba2443e"},{"source":"# Drop rows with missing values in the comments DataFrame\ninitial_comments_count = comments.shape[0]\ncomments.dropna(inplace=True)\ndropped_rows_count = initial_comments_count - comments.shape[0]\n\nprint(f\"Dropped {dropped_rows_count} rows with missing values\")","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1724396710343,"lastExecutedByKernel":"c10077e6-272b-47a9-ae35-69ca37a5a535","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Drop rows with missing values in the comments DataFrame\ninitial_comments_count = comments.shape[0]\ncomments.dropna(inplace=True)\ndropped_rows_count = initial_comments_count - comments.shape[0]\n\nprint(f\"Dropped {dropped_rows_count} rows with missing values\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"0109b6a0-91e1-47e6-8008-ecce36a89ca4","outputs":[{"output_type":"stream","name":"stdout","text":"Dropped 225 rows with missing values\n"}],"execution_count":26}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}